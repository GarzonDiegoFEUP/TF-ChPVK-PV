{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "246f984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e93561",
   "metadata": {},
   "source": [
    "Relevant literature\n",
    "\n",
    "- https://www.researchsquare.com/article/rs-3553470/v1\n",
    "- https://www.nature.com/articles/s41467-020-18661-9#MOESM1\n",
    "\n",
    "Data sets\n",
    "\n",
    "- https://www.sciencebase.gov/catalog/item/6798fd34d34ea8c18376e8ee\n",
    "- https://datacatalog.worldbank.org/search/dataset/0037651\n",
    "- https://en.wikipedia.org/wiki/Abundance_of_elements_in_Earth%27s_crust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "d9eb7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset from https://www.sciencebase.gov/catalog/item/6798fd34d34ea8c18376e8ee\n",
    "\n",
    "year = 2023\n",
    "\n",
    "year_name = {2023: 'PROD_2023',\n",
    "             2024: 'PROD_EST_ 2024'}\n",
    "\n",
    "columns = ['COUNTRY', 'COMMODITY', year_name[year]]\n",
    "\n",
    "df = pd.read_csv('./data/MCS2025_World_Data.csv')\n",
    "\n",
    "df_no_world = df[~df['COUNTRY'].str.contains('World', na=False)].copy()\n",
    "\n",
    "df_max_prod = df_no_world[columns].groupby(['COMMODITY']).sum()[year_name[year]]\n",
    "\n",
    "df_no_world['share_squared'] = (df_no_world[year_name[year]] / df_no_world['COMMODITY'].map(df_max_prod)) ** 2\n",
    "\n",
    "hhi = df_no_world[columns + ['share_squared']].groupby(['COMMODITY']).sum().reset_index()[['COMMODITY', 'share_squared']]\n",
    "\n",
    "hhi.rename(columns={'share_squared': 'HHI'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "8f985843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/mapping/commodity_to_element.json', 'r') as f:\n",
    "    commodity_to_element = json.load(f)\n",
    "\n",
    "hhi['Element'] = hhi['COMMODITY'].map(commodity_to_element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "bbf41891",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/mapping/country_codes.json', 'r') as f:\n",
    "    country_codes = json.load(f)\n",
    "\n",
    "df_no_world['Country_Code'] = df_no_world['COUNTRY'].map(country_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "acf1c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#Dataset from https://datacatalog.worldbank.org/search/dataset/0037651 Year: 2023\n",
    "\n",
    "df_esg = pd.read_csv('./data/ESG_World_Data_2023.csv')\n",
    "\n",
    "# Rename columns in df_esg to the text between square brackets, if present\n",
    "def extract_bracket(col):\n",
    "    match = re.search(r'\\[(.*?)\\]', col)\n",
    "    return match.group(1) if match else col\n",
    "\n",
    "df_esg.columns = [extract_bracket(col) for col in df_esg.columns]\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "positive_indicators = [\n",
    "    'NV.AGR.TOTL.ZS',\n",
    "    'ER.PTD.TOTL.ZS',\n",
    "    'IT.NET.USER.ZS',\n",
    "    'SL.TLF.ACTI.ZS',\n",
    "    'SP.DYN.LE00.IN',\n",
    "    'SG.GEN.PARL.ZS',\n",
    "    'SE.PRM.ENRR',\n",
    "    'CC.EST',\n",
    "    'GE.EST',\n",
    "    'PV.EST',\n",
    "    'RQ.EST',\n",
    "    'RL.EST',\n",
    "    'VA.EST'\n",
    "] #lower-risk\n",
    "\n",
    "negative_indicators = [\n",
    "    'EG.ELC.COAL.ZS',\n",
    "    'EG.IMP.CONS.ZS',\n",
    "    'EG.USE.PCAP.KG.OE',\n",
    "    'EG.USE.COMM.FO.ZS',\n",
    "    'SL.UEM.TOTL.ZS'\n",
    "] #higher-risk\n",
    "\n",
    "def normalize_min_max(series):\n",
    "    min_val = series.min()\n",
    "    max_val = series.max()\n",
    "    return (series - min_val) / (max_val - min_val)\n",
    "\n",
    "for col in df_esg.columns[1:]:\n",
    "    if col not in ['Country Name', 'Country Code', 'Time Code']:\n",
    "        \n",
    "        df_esg[col] = pd.to_numeric(df_esg[col], errors='coerce')\n",
    "\n",
    "        #z-score normalization\n",
    "        df_esg[col] = df_esg[col].transform(lambda x: zscore(x, nan_policy='omit'))\n",
    "\n",
    "    if col in positive_indicators:\n",
    "        df_esg[col] = -df_esg[col] # Invert scores for positive indicators to ensure higher values indicate higher risk\n",
    "\n",
    "# Optional: pillar-specific scores\n",
    "df_esg['E_score'] = df_esg[['NV.AGR.TOTL.ZS','ER.PTD.TOTL.ZS',\n",
    "                            'EG.ELC.COAL.ZS','EG.IMP.CONS.ZS',\n",
    "                            'EG.USE.PCAP.KG.OE','EG.USE.COMM.FO.ZS']].mean(axis=1)\n",
    "\n",
    "df_esg['S_score'] = df_esg[['IT.NET.USER.ZS','SL.TLF.ACTI.ZS','SP.DYN.LE00.IN',\n",
    "                            'SG.GEN.PARL.ZS','SE.PRM.ENRR','SL.UEM.TOTL.ZS']].mean(axis=1)\n",
    "\n",
    "df_esg['G_score'] = df_esg[['CC.EST','GE.EST','PV.EST','RQ.EST','RL.EST','VA.EST']].mean(axis=1)\n",
    "\n",
    "for col in ['E_score', 'S_score', 'G_score']:\n",
    "    df_esg[col] = df_esg[col].transform(lambda x: normalize_min_max(x))\n",
    "\n",
    "df_esg['ESG_score'] = df_esg[['E_score', 'S_score', 'G_score']].mean(axis=1)\n",
    "country_ESG_scores = df_esg.set_index('Country Code')['ESG_score'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "7bdf18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_world['ESG_score'] = df_no_world['Country_Code'].map(country_ESG_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "d263a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhi['SR'] = df_no_world.groupby('COMMODITY').apply(lambda x: np.sum(x['share_squared'] * x['ESG_score'])).reset_index(name='SR')['SR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "c5ce7841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Earth abundance data from https://en.wikipedia.org/wiki/Abundances_of_the_elements_(data_page)\n",
    "\n",
    "df_earth = pd.read_csv('./data/earth_abundance_data.csv')\n",
    "df_earth['Abundance (ppm)'] = pd.to_numeric(df_earth['Abundance (ppm)'], errors='coerce')\n",
    "\n",
    "def normalize_min_max(series):\n",
    "    min_val = series.min()\n",
    "    max_val = series.max()\n",
    "    return (series - min_val) / (max_val - min_val)\n",
    "\n",
    "df_earth['Silicio_normalized'] = df_earth['Abundance (ppm)'] / df_earth.loc[df_earth['Symbol'] == 'Si', 'Abundance (ppm)'].values[0]\n",
    "\n",
    "df_earth['normalized_abundance_risk'] = 1 - normalize_min_max(df_earth['Silicio_normalized'])\n",
    "\n",
    "element_abundance = df_earth.set_index('Symbol')['normalized_abundance_risk'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "2626d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_element(val, target):\n",
    "    if isinstance(val, list):\n",
    "        return target in val\n",
    "    elif isinstance(val, str):\n",
    "        return target == val\n",
    "    return False\n",
    "\n",
    "\n",
    "def find_hhi_score(formula, hhi=hhi, element_abundance=element_abundance):\n",
    "\n",
    "    elements = re.findall(r'[A-Z][a-z]?', formula)\n",
    "\n",
    "    warn = ''\n",
    "\n",
    "    hhi_copy = hhi.copy()\n",
    "    for element in elements:\n",
    "        hhi_copy['has_' + element] = hhi_copy['Element'].apply(lambda x: contains_element(x, element))\n",
    "    \n",
    "    hhi_copy['has_element'] = hhi_copy[[col for col in hhi_copy.columns if col.startswith('has_')]].sum(axis=1)\n",
    "\n",
    "    if hhi_copy['has_element'].sum() == 0:\n",
    "        return None, None, None\n",
    "    elif hhi_copy['has_element'].sum() < len(elements):\n",
    "        print(f\"Warning: Not all elements found in HHI data for the compound {formula}, the elements found are:\")\n",
    "        print(hhi_copy[hhi_copy['has_element'] != 0]['Element'].values)\n",
    "\n",
    "        warn = f\"Warning: Not all elements found in HHI data for the compound {formula}, the elements found are: {hhi_copy[hhi_copy['has_element'] != 0]['Element'].values}\"\n",
    "\n",
    "\n",
    "    hhi_value = (hhi_copy['HHI'] * hhi_copy['has_element']).sum()\n",
    "    sr_value = (hhi_copy['SR'] * hhi_copy['has_element']).sum()\n",
    "\n",
    "    #calculate abundance risk as the sum of normalized abundance risks of the elements in the formula\n",
    "    ar_value = sum([element_abundance.get(element, 0) for element in elements])/len(elements)\n",
    "\n",
    "    return [hhi_value, sr_value, ar_value, warn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "e4f59670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Not all elements found in HHI data for the compound SrUSe3, the elements found are:\n",
      "['Se' 'Sr']\n",
      "Warning: Not all elements found in HHI data for the compound CeUSe3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'Se']\n",
      "Warning: Not all elements found in HHI data for the compound SrUS3, the elements found are:\n",
      "['Sr' 'S']\n",
      "Warning: Not all elements found in HHI data for the compound UInS3, the elements found are:\n",
      "['In' 'S']\n",
      "Warning: Not all elements found in HHI data for the compound EuUS3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'S']\n",
      "Warning: Not all elements found in HHI data for the compound EuScS3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'S']\n",
      "Warning: Not all elements found in HHI data for the compound LaTlS3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'S']\n",
      "Warning: Not all elements found in HHI data for the compound CeScS3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'S']\n",
      "Warning: Not all elements found in HHI data for the compound EuUSe3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'Se']\n",
      "Warning: Not all elements found in HHI data for the compound TbScS3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'S']\n",
      "Warning: Not all elements found in HHI data for the compound BaUS3, the elements found are:\n",
      "['Ba' 'S']\n",
      "Warning: Not all elements found in HHI data for the compound GdScS3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'S']\n",
      "Warning: Not all elements found in HHI data for the compound ScUS3, the elements found are:\n",
      "['S']\n",
      "Warning: Not all elements found in HHI data for the compound LaScS3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'S']\n",
      "Warning: Not all elements found in HHI data for the compound UCdS3, the elements found are:\n",
      "['Cd' 'S']\n",
      "Warning: Not all elements found in HHI data for the compound SmScS3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'S']\n",
      "Warning: Not all elements found in HHI data for the compound DyScS3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'S']\n",
      "Warning: Not all elements found in HHI data for the compound BaUSe3, the elements found are:\n",
      "['Ba' 'Se']\n",
      "Warning: Not all elements found in HHI data for the compound SmUSe3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'Se']\n",
      "Warning: Not all elements found in HHI data for the compound PrScS3, the elements found are:\n",
      "[list(['La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Y'])\n",
      " 'S']\n"
     ]
    }
   ],
   "source": [
    "# Try on CrystaLLM results\n",
    "\n",
    "df_results = pd.read_csv('./data/results CrystaLLM.csv')\n",
    "df_results[['HHI', 'SR', 'AR', 'Warning']] = df_results['material'].apply(lambda x: pd.Series(find_hhi_score(x)))\n",
    "\n",
    "df_results[['material', 'HHI', 'SR', 'AR', 'Warning']].to_csv('./data/results_HHI.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a4610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
